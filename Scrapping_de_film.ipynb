{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slh09dxjDZOt"
      },
      "source": [
        "from time import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "start = time()\n",
        "\n",
        "liste_d_information=[] #creation d'une liste dans laquelle nous allons rajouter les informations de chaque films\n",
        "liste_de_page=[]# creation d'une liste dans laquelle nous allons rajouter les liens de chaque serie\n",
        "url_base= 'https://www.imdb.com'\n",
        "\n",
        "liste_de_page.append('https://www.imdb.com/search/title/?at=0&num_votes=5000,&sort=user_rating,desc&start=1&title_type=feature')#ajouter le lien de la page principale dans le tableau\n",
        "\n",
        "#requette sur la premiere page\n",
        "r = requests.get(url_base +'/search/title/?at=0&num_votes=5000,&sort=user_rating,desc&start=1&title_type=feature') # effectuer une requette de recuperation des donneesvers le site\n",
        "data=r.text  # pour extraire les\n",
        "soup = BeautifulSoup(data, 'html.parser')#pour permettre la manipulation avec la librarie BeautifulSoup donnees html\n",
        "\n",
        " #recuperation de l'url de la page suivante\n",
        "boutton_next_url=url_base +soup.find_all('a',{'class':\"next-page\"})[0]['href']\n",
        "liste_de_page.append(boutton_next_url)\n",
        "compteur=0\n",
        "while (boutton_next_url and compteur<1 ):\n",
        "\n",
        "    compteur=compteur+1\n",
        "\n",
        "\n",
        "    liste_de_page.append(boutton_next_url)\n",
        "    r_= requests.get(boutton_next_url)\n",
        "    data_=r_.text\n",
        "    soup_ = BeautifulSoup(data_, 'html.parser')\n",
        "    if soup_.find_all('a',{'class':\"next-page\"}):\n",
        "\n",
        "        boutton_next_url=url_base + soup_.find_all('a',{'class':\"next-page\"})[0]['href']\n",
        "        r_1 = requests.get(boutton_next_url)\n",
        "        data_1=r_1.text\n",
        "        soup_1 = BeautifulSoup(data_, 'html.parser')\n",
        "        balise_lien_film=soup_1.find_all ('h3',{'class': 'lister-item-header'})\n",
        "        if soup_.find_all('a',{'class':\"next-page\"}):\n",
        "            for j in range (0,len(balise_lien_film)):\n",
        "                lien_de_film= 'https://www.imdb.com'+ balise_lien_film[j].contents[3]['href']+'?ref_=adv_li_tt'\n",
        "\n",
        "                print(lien_de_film)\n",
        "\n",
        "        #       #  LE TITRE DU FILM\n",
        "                r1 = requests.get(lien_de_film) # effectuer une requette de recuperation des donneesvers le site\n",
        "                data1=r1.text  # pour extraire les donnees html\n",
        "                soup1 = BeautifulSoup(data1, 'html.parser')#pour permettre la manipulation avec la librarie BeautifulSoup\n",
        "                balise_episode=soup1.find_all ('div',{'class': 'title_wrapper'})\n",
        "\n",
        "                if balise_episode and balise_episode[0] and balise_episode[0].contents[1] :\n",
        "                    balise_nom= balise_episode[0].contents[1].text.replace('\\xa0','' ).strip()\n",
        "                    Titre_film=balise_nom [:-6]\n",
        "                else :\n",
        "                    Titre_film = \"XXX\"\n",
        "                print(Titre_film) #pour supprimer l'espace en debut et en fin\n",
        "\n",
        "                #LA NOTE\n",
        "                note_film=soup1.find_all ('span',{'itemprop': 'ratingValue'})\n",
        "                Note_film =note_film[0].text if note_film else 'xxx'# Ainsi on obtient le score de l'episode\n",
        "                print(Note_film)\n",
        "\n",
        "                #le score\n",
        "\n",
        "                score=soup1.find_all ('div',{'class': 'metacriticScore'})\n",
        "                Score =score[0].find('span').text if score else 'xxx'# Ainsi on obtient le score de l'episode\n",
        "                print(Score)\n",
        "\n",
        "\n",
        "                #le nombre de vote\n",
        "                nbre_votes=soup1.find_all ('span',{'itemprop': 'ratingCount'})\n",
        "                Nbre_de_vote = nbre_votes[0].text.replace(',','.') if nbre_votes else 'xxx'# Ainsi on obtient le nombre de vote\n",
        "                print(Nbre_de_vote)\n",
        "\n",
        "\n",
        "                 #le directeur\n",
        "                directeur = soup1.find_all ('div',{'class': 'credit_summary_item'})   # Ainsi on obtien le nom du ou des directeur(s)\n",
        "                Directeur=directeur[0].contents[3].text if directeur and directeur[0] and directeur[0].contents[3]   else 'xxx'#+ ' ,' + directeur[0].contents[5].text)\n",
        "                print(Directeur)\n",
        "\n",
        "                #le scenariste\n",
        "                scenariste =soup1.find_all ('div',{'class': 'credit_summary_item'})\n",
        "                if scenariste and scenariste[1] and scenariste[1].contents[3] :\n",
        "                    Scenariste=scenariste[1].contents[3].text\n",
        "                else :\n",
        "                    Scenariste = \"XXX\"\n",
        "\n",
        "                print(Scenariste)\n",
        "\n",
        "                #la duree du film\n",
        "                duree_film= soup1.find ('time') # Ainsi on obtient la duree de l'episode\n",
        "                Duree_film=duree_film.text.replace('\\n','').strip() if duree_film else 'xxx'\n",
        "                print(Duree_film) # pour remplacer le \\n PAR L'espaceinsi on obtient la duree de l'episode\n",
        "\n",
        "                #le type de film(comdedie, drame, romance,...)\n",
        "                type_film= soup1.find_all ('div',{'class': 'subtext'})\n",
        "                Type_film=type_film[0].contents[7].text if type_film and type_film[0] and type_film[0].contents[7] else 'XXX'## Ainsi on obtient le type de l'episode\n",
        "                print(Type_film)\n",
        "\n",
        "                #date de sortie du film\n",
        "                date_sortie=soup1.find_all('h4',text='Release Date:')# Ainsi on obtient la date de sortie de l'episode\n",
        "                Date_sortie= date_sortie[0].find_parent().contents[2] if date_sortie  else 'XXX'\n",
        "                print(Date_sortie)\n",
        "\n",
        "                #pays DE SORTIE DU FILM\n",
        "                pays_sortie =soup1.find_all('h4',text='Country:') #Ainsi on obtient le lieu de tournage\n",
        "                Pays_sortie =pays_sortie [0].find_parent().find('a').text  if pays_sortie and pays_sortie [0]  else 'XXX'\n",
        "                print(Pays_sortie )\n",
        "\n",
        "\n",
        "                #lieu de tournage\n",
        "                lieu_tournage=soup1.find_all('h4',text='Filming Locations:') #Ainsi on obtient le lieu de tournage\n",
        "                Lieu_tournage=lieu_tournage[0].find_parent().find('a').text  if lieu_tournage and lieu_tournage[0] else 'XXX'\n",
        "                print(Lieu_tournage)\n",
        "#\n",
        "#                #la langue de tournage\n",
        "                langue_tournage=soup1.find_all('h4',text='Language:')\n",
        "                Langue_tournage= langue_tournage[0].find_parent().find('a').text if langue_tournage and langue_tournage[0] else 'XXX'\n",
        "                print(Langue_tournage)\n",
        "\n",
        "                review=soup1.find_all ('div',{'class': 'titleReviewbarItemBorder'})\n",
        "                Nmbre_review=\"XXX\"\n",
        "                Nombre_critic=\"XXX\"\n",
        "\n",
        "                if review:\n",
        "                    review=review[0].find_all('a')\n",
        "                    if len(review)==2:\n",
        "                        Nmbre_review=review[0].text.split('user')[0]\n",
        "                        Nombre_critic=review[1].text.split('critic')[0]\n",
        "                    else:\n",
        "                        if review[0] and \"user\" in review[0].text:\n",
        "                            Nmbre_review=review[0].text.split('user')[0]\n",
        "                        if review[0] and \"critic\" in review[0].text:\n",
        "                            Nombre_critic=review[0].text.split('critic')[0]\n",
        "\n",
        "\n",
        "                #le nombre de review\n",
        "                print(Nmbre_review)\n",
        "                #le nombre de critique\n",
        "                print(Nombre_critic)\n",
        "\n",
        "                #la filmographie\n",
        "                Filmographie ='' # creation d'une liste dans laquelle nous allons rajouter les liens de chaque film faisant partie de la filmographie\n",
        "                scenariste = soup1.find_all('div',{'class': 'credit_summary_item'}) #Ainsi on obtient le nom du scenarite\n",
        "                if scenariste and scenariste[1] and scenariste[1].contents[3] and scenariste[1].contents[3]['href'] :\n",
        "                    url_filmographie ='https://www.imdb.com' + scenariste[1].contents[3]['href'] + '?ref_=tt_ov_wr'\n",
        "                    r_filmo = requests.get(url_filmographie) # effectuer une requette de recuperation des donneesvers le site\n",
        "                    data_filmo = r_filmo .text  # pour extraire les donnees html\n",
        "                    soup_filmo = BeautifulSoup(data_filmo, 'html.parser')#\n",
        "                    filmographie = soup_filmo.find_all ('div',{'class': \"filmo-row odd\"})# Ainsi on obtient le lieu de sortie de l'episode\n",
        "                    if filmographie:\n",
        "                        for a in range (0,len(filmographie)): # boucle pour la recuperation des 23titres de films\n",
        "\n",
        "                            if filmographie[a] and filmographie[a].contents[3] :\n",
        "                                filmo= filmographie[a].contents[3].text\n",
        "                                Filmographie= Filmographie+ ','+ filmo\n",
        "                            else :\n",
        "                                Filmographie= 'XXX'\n",
        "                    else:\n",
        "                        Filmographie= 'XXX'\n",
        "\n",
        "                else :  Filmographie= 'XXX'\n",
        "\n",
        "                print(Filmographie)\n",
        "\n",
        "                #Run time\n",
        "                runtime=soup1.find_all('h4',text='Runtime:') #Ainsi on obtient le lieu de tournage\n",
        "                Runtime=runtime[0].find_parent().find('time').text  if runtime and runtime[0] else 'XXX'\n",
        "                print(Runtime)\n",
        "\n",
        "\n",
        "\n",
        "                #color\n",
        "                color=soup1.find_all('h4',text='Color:') #Ainsi on obtient le lieu de tournage\n",
        "                Color=color[0].find_parent().find('a').text  if color and color[0] else 'XXX'\n",
        "                print(Color)\n",
        "\n",
        "\n",
        "                #aspect ratio\n",
        "                aspect_ratio= soup1.find_all('h4',text='Aspect Ratio:')# Ainsi on obtient la date de sortie de l'episode\n",
        "                Aspect_ratio= aspect_ratio[0].find_parent().contents[2] if aspect_ratio and aspect_ratio[0] and aspect_ratio[0].find_parent().contents[2]  else 'XXX'\n",
        "                print(Aspect_ratio)\n",
        "\n",
        "                #budget\n",
        "                budget= soup1.find_all('h4',text='Budget:')# Ainsi on obtient la date de sortie de l'episode\n",
        "                Budget= budget[0].find_parent().contents[2].replace(',','.')[1:]+'$'if budget and budget[0] and budget[0].find_parent().contents[2]  else 'XXX'\n",
        "                print(Budget)\n",
        "\n",
        "\n",
        "                #le  C_Worldwide_Gross\n",
        "                cwg= soup1.find_all('h4',text='Cumulative Worldwide Gross:')# Ainsi on obtient la date de sortie de l'episode\n",
        "                Cwg=  cwg[0].find_parent().contents[2].replace(',','.')[1:]+'$'if  cwg and cwg[0] and cwg[0].find_parent().contents[2] else 'XXX'\n",
        "                print(Cwg)\n",
        "\n",
        "\n",
        "                # le sound mix:\n",
        "                Sound_Mix=''\n",
        "                sound_Mix= soup1.find_all('h4',text='Sound Mix:')# Ainsi on obtient la date de sortie de l'episode\n",
        "                sound_Mix= sound_Mix[0].find_parent().find_all('a') if sound_Mix and sound_Mix[0] else 'XXX'\n",
        "                if sound_Mix != 'XXX':\n",
        "                    for y in range(0,len(sound_Mix)):\n",
        "                        if sound_Mix[y] :\n",
        "                            Sound_Mix=sound_Mix[y].text + ' '+ Sound_Mix\n",
        "\n",
        "                print(Sound_Mix)\n",
        "\n",
        "                #Le Revenue généré aux USA (Gross USA)\n",
        "                gross_USA= soup1.find_all('h4',text='Gross USA:')# Ainsi on obtient la date de sortie de l'episode\n",
        "                Gross_USA=  gross_USA[0].find_parent().contents[2].replace(',','.')[1:]+'$' if  gross_USA and gross_USA[0] and gross_USA[0].find_parent().contents[2] else 'XXX'\n",
        "                print(Gross_USA)\n",
        "                print(\"________________________________________________________\")\n",
        "\n",
        "                liste_d_information.append((Titre_film, Note_film, Score, Nbre_de_vote, Directeur, Scenariste, Duree_film, Type_film, Date_sortie, Lieu_tournage, Pays_sortie, Langue_tournage, Nmbre_review, Nombre_critic, Filmographie, Budget, Runtime, Color,  Aspect_ratio, Gross_USA, Cwg, Sound_Mix))       #liste_d_information.append(())\n",
        "\n",
        "\n",
        "df = pd.DataFrame(liste_d_information, columns=['Titre_film', 'Note_film', 'Score', 'Nbre_de_vote', 'Directeur', 'Scenariste', 'Duree_film', 'Type_film', 'Date_sortie', 'Lieu_tournage','pays de ritie', 'Langue_tournage', 'Nmbre_review', 'Nombre_critic', 'Filmographie', 'Budget', 'Runtime', 'Color',  'Aspect_ratio', 'Gross_USA', 'Cwg', 'Sound_Mix'])\n",
        "df.to_csv('imdb.csv', index=False, encoding='utf-8')\n",
        "pd.set_option('display.max_row',df.shape[0])\n",
        "pd.set_option('display.max_column',df.shape[1])\n",
        "print(df)\n",
        "\n",
        "\n",
        "end = time()\n",
        "print (\"ce code s'est executé en: {:.4f} secondes\".format(end - start))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}